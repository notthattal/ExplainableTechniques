{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r48k4EHbnErv"
      },
      "source": [
        "## AIPI 590 - XAI | Assignment #5\n",
        "### Explainable Techniques\n",
        "#### Author: Tal Erez\n",
        "#### Colab Notebook:\n",
        "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/notthattal/ExplainableTechniques/blob/main/explainable_techniques.ipynb)\n",
        "\n",
        "### To Run in Colab\n",
        "\n",
        "Verify you are running on a GPU. On the top right of the screen click the down arrow in between \"RAM/Disk\" and \"Gemini\"  -> Change Runtime Type -> T4 GPU -> Save\n",
        "\n",
        "### Introduction\n",
        "This notebook demonstrates how to use LIME to generate local explanations for images. The images used come from a small version of the ImageNet library, and the pretrained model used for predictions is ResNet34. For a given label, this will output LIME's explanations for each image of that label in the dataset.\n",
        "\n",
        "### To Run The WebApp\n",
        "If you would like to run the webapp that was created alongside this notebook:\n",
        "#### 1. Open the terminal and cd into the root of this directory\n",
        "#### 2. Run the following command:\n",
        "```\n",
        "streamlit run webapp/streamlit_app.py\n",
        "```\n",
        "#### 3. To close the connection exit out of the site and type control+C in the terminal\n",
        "\n",
        "### Install required dependencies and import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkGwJHYRnErv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Remove Colab default sample_data if it exists\n",
        "if os.path.exists(\"./sample_data\"):\n",
        "    !rm -r ./sample_data\n",
        "\n",
        "# Clone GitHub files to colab workspace\n",
        "repo_name = \"ExplainableTechniques\"\n",
        "\n",
        "# Check if the repo already exists\n",
        "if not os.path.exists(\"/content/\" + repo_name):\n",
        "    git_path = 'https://github.com/notthattal/ExplainableTechniques.git'\n",
        "    !git clone \"{git_path}\"\n",
        "else:\n",
        "    print(f\"{repo_name} already exists.\")\n",
        "\n",
        "# Change working directory to location of notebook\n",
        "path_to_notebook = os.path.join(\"/content/\" + repo_name)\n",
        "%cd \"{path_to_notebook}\"\n",
        "%ls\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "import json\n",
        "from lime import lime_image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import urllib.request\n",
        "from urllib.error import HTTPError\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpOcClCJnErw"
      },
      "source": [
        "### Install the required dependencies and import the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQH0EZiJnErw"
      },
      "outputs": [],
      "source": [
        "device = None\n",
        "\n",
        "# Fetching the device that will be used throughout this notebook\n",
        "if torch.backends.mps.is_available():\n",
        "    # Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "    torch.use_deterministic_algorithms(True)\n",
        "\n",
        "    #set device to use mps\n",
        "    device = torch.device(\"mps\")\n",
        "elif torch.cuda.is_available():\n",
        "    # Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    #set device to use cuda\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    #set device to use the cpu\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Using device\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwMRe_ySnErw"
      },
      "source": [
        "### Download the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pPDFcqBnErw"
      },
      "outputs": [],
      "source": [
        "# Github URL where the dataset is stored for this tutorial\n",
        "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial10/\"\n",
        "\n",
        "# Create paths if they don't exist yet\n",
        "DATASET_PATH = \"./data\"\n",
        "\n",
        "os.makedirs(DATASET_PATH, exist_ok=True)\n",
        "\n",
        "# For each file, check whether it already exists. If not, try downloading it.\n",
        "file_name = \"TinyImageNet.zip\"\n",
        "file_path = os.path.join(DATASET_PATH, file_name)\n",
        "if not os.path.isfile(file_path):\n",
        "    file_url = base_url + file_name\n",
        "    print(f\"Downloading {file_url}...\")\n",
        "    try:\n",
        "        urllib.request.urlretrieve(file_url, file_path)\n",
        "    except HTTPError as e:\n",
        "        print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)\n",
        "    if file_name.endswith(\".zip\"):\n",
        "        print(\"Unzipping file...\")\n",
        "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(file_path.rsplit(\"/\",1)[0])\n",
        "            print(\"Unzip complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69ToW1W-nErw"
      },
      "source": [
        "### Load the ImageNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uf2Ttu2znErw"
      },
      "outputs": [],
      "source": [
        "# Load a pre-trained ResNet-34 model with ImageNet weights\n",
        "pretrained_model = models.resnet34(weights='IMAGENET1K_V1')\n",
        "pretrained_model = pretrained_model.to(device)\n",
        "\n",
        "# Set model to evaluation mode\n",
        "pretrained_model.eval()\n",
        "\n",
        "# Specify that no gradients needed for the network\n",
        "for p in pretrained_model.parameters():\n",
        "    p.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nRGVyHQnErw"
      },
      "source": [
        "### Load the Dataset and Label Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BylOr7FnErw"
      },
      "outputs": [],
      "source": [
        "# Load dataset and create data loader\n",
        "imagenet_path = os.path.join(DATASET_PATH, \"TinyImageNet/\")\n",
        "assert os.path.isdir(imagenet_path), f\"Could not find the ImageNet dataset at expected path \\\"{imagenet_path}\\\". \" + \\\n",
        "                                     f\"Please make sure to have downloaded the ImageNet dataset here, or change the {DATASET_PATH=} variable.\"\n",
        "\n",
        "# Load label names to interpret the label numbers 0 to 999\n",
        "with open(os.path.join(imagenet_path, \"label_list.json\"), \"r\") as f:\n",
        "    label_names = json.load(f)\n",
        "\n",
        "# get a list of folders in sorted order for retrieving pictures by label\n",
        "folders = sorted([f for f in os.listdir(imagenet_path) if os.path.isdir(os.path.join(imagenet_path, f))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNrCKPecnErw"
      },
      "source": [
        "### Get all images for a specific label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw66BOirnErw"
      },
      "outputs": [],
      "source": [
        "def get_images(label_name):\n",
        "    '''\n",
        "    gets a list of images in RGB format by label name from the TinyImageNet dataset\n",
        "\n",
        "    Inputs:\n",
        "        label_name (str): the label for which to retrieve the images\n",
        "\n",
        "    Return:\n",
        "        images (list): a list of the images retrieved\n",
        "    '''\n",
        "    #get the index of the label from label_list.json\n",
        "    index = label_names.index(label_name)\n",
        "\n",
        "    #get the corresponding folder of images from TinyImageNet\n",
        "    folder = imagenet_path + folders[index] + '/'\n",
        "\n",
        "    #get the images from the selected folder\n",
        "    image_names = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
        "\n",
        "    images = []\n",
        "    for image_name in image_names:\n",
        "        #open the image\n",
        "        with open(os.path.relpath(folder + image_name), 'rb') as f:\n",
        "            with Image.open(f) as img:\n",
        "                #convert the image to RGB and add it to the output list\n",
        "                images.append(img.convert('RGB'))\n",
        "\n",
        "    return images\n",
        "\n",
        "#get the images by label\n",
        "images_rgb = get_images('wallaby')\n",
        "\n",
        "#show the images\n",
        "for img in images_rgb:\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNF9uJqLnErw"
      },
      "source": [
        "### Create Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cq0lKAp2nErw"
      },
      "outputs": [],
      "source": [
        "# Set the Mean and Std from ImageNet\n",
        "NORM_MEAN = np.array([0.485, 0.456, 0.406])\n",
        "NORM_STD = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "# Convert the input image to PyTorch Tensor, normalize the images using the mean and standard deviation above and\n",
        "plain_transforms = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=NORM_MEAN,\n",
        "                             std=NORM_STD)\n",
        "    ])\n",
        "\n",
        "# Resize and take the center part of image to what our model expects\n",
        "pil_transf = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.CenterCrop(224)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-jRII9GnErw"
      },
      "source": [
        "### Create a Function to Get Predictions From an Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvTCw-fTnErx"
      },
      "outputs": [],
      "source": [
        "def batch_predict(image):\n",
        "    '''\n",
        "    Add a batch dimension to a Pytorch tensor, get predictions from the model, and return the probabilities\n",
        "\n",
        "    Input:\n",
        "        image (Pytorch Tensor): the image used for prediction\n",
        "\n",
        "    Return:\n",
        "        A numpy array of the computed probabilities\n",
        "    '''\n",
        "    # apply transformations to each image and stack them into a batch (a tensor) along a new dimension.\n",
        "    batch = torch.stack(tuple(plain_transforms(i) for i in image), dim=0)\n",
        "\n",
        "    # move the batch to the device\n",
        "    batch = batch.to(device)\n",
        "\n",
        "    # feed the batch to the model to get the logits\n",
        "    logits = pretrained_model(batch)\n",
        "\n",
        "    # convert logits to probabilities\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "\n",
        "    # detach the computed probabilities from the computational graph, move them back to the CPU and convert them into a numpy array\n",
        "    return probs.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khqbz8G6nErx"
      },
      "source": [
        "### Verify The Model is Correctly Predicting The Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfC4B0tcnErx"
      },
      "outputs": [],
      "source": [
        "# get predictions for each image\n",
        "for i in range(len(images_rgb)):\n",
        "    # get predictions from the model\n",
        "    test_pred = batch_predict([pil_transf(images_rgb[i])])\n",
        "\n",
        "    # get the label corresponding to the highest prediction\n",
        "    print(\"Prediction for Image: \" + str(i + 1) + \": \" + label_names[test_pred.squeeze().argmax()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOChMSPRnErx"
      },
      "source": [
        "### Run Lime And Get The Explanations\n",
        "- Generates an explanation for a single image\n",
        "- resizes and crops the image\n",
        "- uses batch_predict to get the prediction\n",
        "- gets the top 5 predicted labels\n",
        "- num_samples=1000 will have LIME generate 1000 variations of the image to see how the prediction changes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfvUE-b9nErx"
      },
      "outputs": [],
      "source": [
        "# instantiate the LimeImageExplainer and explanations array\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "explanations = []\n",
        "\n",
        "# get explanations for each image\n",
        "for img in images_rgb:\n",
        "    explanations.append(explainer.explain_instance(np.array(pil_transf(img)),\n",
        "                                            batch_predict, # classification function\n",
        "                                            top_labels=5,\n",
        "                                            hide_color=0,\n",
        "                                            num_samples=1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRouOBnTnErx"
      },
      "source": [
        "### Show The Explanations\n",
        "- show the images with the explanations overlayed for each image in the label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INOQUEzmnErx"
      },
      "outputs": [],
      "source": [
        "for explanation in explanations:\n",
        "    # get the image and mask for each image\n",
        "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=10, hide_rest=True)\n",
        "\n",
        "    # normalize the image to range [0, 1]\n",
        "    temp = temp.astype(float) / 255.0\n",
        "\n",
        "    # convert mask to bool to apply changes to the unimportant part of the image\n",
        "    mask = mask.astype(bool)\n",
        "\n",
        "    # Create a gray image to replace the unimportant parts\n",
        "    gray_image = np.ones_like(temp) * 0.5\n",
        "\n",
        "    # Combine the important parts of the original image and the gray image for the unimportant parts\n",
        "    temp[~mask] = gray_image[~mask]\n",
        "\n",
        "    # Add boundaries to the image\n",
        "    img_boundry2 = mark_boundaries(temp, mask)\n",
        "\n",
        "    # plot and show the images\n",
        "    plt.imshow(img_boundry2)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taGNeJknnErx"
      },
      "source": [
        "## Discussion\n",
        "LIME (local interpretable model-agnostic explanations) was chosen because LIME works with image data (which is the data chosen for this project) and the explanations generated by the model are intuitive to understand. Pros to LIME in general, but not necesarily for the case of this notebook, is that it is model agnostic meaning we could switch out Resnet34 and still use this explanable method. It also works with text and tabular data along with image data. Some limitations to LIME are that (especially for higher dimensional feature spaces) there isn't a robust method of finding the optimal kernel width for the exponential smoothing kernel used in its implementation. LIME explanations can also be inconsistent, LIME can be used to hide biases and it can be easily fooled.  \n",
        "\n",
        "## Citations:\n",
        "\n",
        "Lippe, Phillip, & Bent, Brinnae, PhD \"Tutorial 10: Adversarial attacks.\" Github, 2024, https://github.com/AIPI-590-XAI/Duke-AI-XAI/blob/main/explainable-ml-example-notebooks/local_explanations.ipynb\n",
        "\n",
        "[Shah, Shital](https://github.com/sytelus) \"Tutorial - images - Pytorch.\" Github, 2019, https://github.com/marcotcr/lime/blob/master/doc/notebooks/Tutorial%20-%20images%20-%20Pytorch.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
